import re

from mathruler.grader import extract_boxed_content, grade_answer
from openai import OpenAI

client = OpenAI(
    base_url="http://127.0.0.1:1225/v1",
    api_key="EMPTY",
)

SYSTEM_PROMPT = """You are a careful and disciplined problem solver that follows a given guideline to reason step by step and produce the final answer.

You are provided with:
(1) A QUESTION that needs to be solved.
(2) A GUIDELINE generated by another model that describes how to approach the problem.

Your task:
- STRICTLY follow the provided guideline to perform reasoning.
- You must first think about the reasoning process as an internal monologue before giving the final answer.
- The reasoning process MUST be enclosed within <think> </think> tags.
- The final answer MUST be placed inside \\boxed{}.
- When performing reasoning, use precise and mathematical logic, not vague explanations.
- Do NOT reveal hidden reasoning outside of the <think> block.
- If the guideline has gaps, fill them in coherently without deviating from its intent.

Format:
<think>
Your detailed internal reasoning process, including any calculations, logic, or derivations.
</think>
\\boxed{your final answer here}"""




def format_reward(predict_str: str) -> float:
    pattern = re.compile(r"<think>.*</think>.*\\boxed\{.*\}.*", re.DOTALL)
    match_result = re.fullmatch(pattern, predict_str)
    return 1.0 if match_result else 0.0


def acc_reward(predict_str: str, ground_truth: str, use_boxed: bool = True) -> float:
    if use_boxed:
        answer = extract_boxed_content(predict_str)
    else:
        answer = predict_str
    return 1.0 if grade_answer(answer, ground_truth) else 0.0


def compute_score(predict_str: str, ground_truth: str, use_boxed: bool = True, format_score: float = 0.1, extra_info: dict = None) -> float:
    completion = client.chat.completions.create(
        model="Qwen2.5-3B-Instruct",
        messages=[
            {
            "role": "user",
            "content": SYSTEM_PROMPT + "\n\n" + "Question: " + extra_info["question"] + "\n\n" + "Guideline: " + predict_str
            }
        ],
        temperature=1.0,      # 0.0~1.2 常用，越低越稳，越高越有创造性
        max_tokens=2048        # 本次回复最多生成的 token 数
    )
    predict_str_solver = completion.choices[0].message.content
    
    
    return (1.0 - format_score) * acc_reward(predict_str_solver, ground_truth, use_boxed) + format_score * format_reward(
        predict_str
    )
